{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[86],{195:function(t,s,a){\"use strict\";a.r(s);var n=a(0),e=Object(n.a)({},function(){this.$createElement;this._self._c;return this._m(0)},[function(){var t=this,s=t.$createElement,a=t._self._c||s;return a(\"div\",{staticClass:\"content\"},[a(\"h1\",{attrs:{id:\"set-和-map-数据结构\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#set-和-map-数据结构\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" Set 和 Map 数据结构\")]),a(\"h2\",{attrs:{id:\"set\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#set\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" Set\")]),a(\"p\",[t._v(\"Set 类似于数组，但是成员的值都是唯一的，没有重复的值。\")]),a(\"p\",[t._v(\"使用 Set 构造函数, 生成 Set 数据结构.  Set 函数可以接受一个数组（或者具有 iterable 接口的其他数据结构）作为参数，用来初始化。\")]),a(\"div\",{staticClass:\"language-js extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" s \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token class-name\"}},[t._v(\"Set\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"3\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"5\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"4\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"5\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"forEach\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=>\")]),t._v(\" s\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"add\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"x\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"for\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"let\")]),t._v(\" i \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"of\")]),t._v(\" s\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"{\")]),t._v(\"\\n  console\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\".\")]),a(\"span\",{attrs:{class:\"token function\"}},[t._v(\"log\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),t._v(\"i\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"}\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token comment\"}},[t._v(\"// 没有重复值\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token comment\"}},[t._v(\"// 2 3 5 4\")]),t._v(\"\\n\\n\"),a(\"span\",{attrs:{class:\"token comment\"}},[t._v(\"// -----------------------\")]),t._v(\"\\n\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"const\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"set\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token class-name\"}},[t._v(\"Set\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"1\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"2\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"3\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"4\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"4\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"...\")]),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"set\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token comment\"}},[t._v(\"// [1, 2, 3, 4]\")]),t._v(\"\\n\")])])]),a(\"div\",{staticClass:\"warning custom-block\"},[a(\"p\",{staticClass:\"custom-block-title\"},[t._v(\"注意\")]),a(\"p\",[a(\"code\",[t._v(\"NaN\")]),t._v(\" 在 Set 中是被认为相等的.\")]),a(\"div\",{staticClass:\"language-js extra-class\"},[a(\"pre\",{pre:!0,attrs:{class:\"language-js\"}},[a(\"code\",[a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"let\")]),t._v(\" a \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"NaN\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" b \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token number\"}},[t._v(\"NaN\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"let\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"set\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token operator\"}},[t._v(\"=\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"new\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token class-name\"}},[t._v(\"Set\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"(\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"[\")]),t._v(\"a\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\",\")]),t._v(\" b\"),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\"]\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\")\")]),a(\"span\",{attrs:{class:\"token punctuation\"}},[t._v(\";\")]),t._v(\"\\n\"),a(\"span\",{attrs:{class:\"token keyword\"}},[t._v(\"set\")]),t._v(\" \"),a(\"span\",{attrs:{class:\"token comment\"}},[t._v(\"// Set {NaN}\")]),t._v(\"\\n\")])])])]),a(\"h2\",{attrs:{id:\"map\"}},[a(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#map\",\"aria-hidden\":\"true\"}},[t._v(\"#\")]),t._v(\" Map\")])])}],!1,null,null,null);s.default=e.exports}}]);","extractedComments":[]}