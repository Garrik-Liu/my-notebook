# 复杂度分析

简单说, 复杂度分析就是不用具体的测试数据来测试，就可以粗略地估计算法的执行效率的方法

## 大 O 复杂度表示法

算法的执行效率，粗略地讲，就是算法代码执行的时间。

先举个例子:

``` C
int cal(int n) { 
    int sum = 0;

    for(int i = 0; i <= n; i++) {
        sum += i; 
    }

    return sum;
}
```

看上面这一段代码, 求 1,2,3…n 的累加和.  估算一下这段代码的执行时间。这段代码的每一行都执行着类似的操作：读数据-运算-写数据。假设每行代码执行的时间都一样，为  unit_time。

第 2、3 行代码分别需要 1 个 unit_time 的执执行时间，第 4、5 行都运行了 n 遍，所以需要 `2n * unit_time` 的执行时间，所以这段代码总的执行时间就是 `(2n+2) * unit_time`

可以看出来，所有代码的执行时间 T(n) 与**每行代码的执行次数成正比**。

这个规律总结成一个公式:

![22900968aa2b190072c985a08b0e92ef](https://i.imgur.com/lqlpF7W.png)


* `T(n)` 我们已经讲过了，它表示代码执行的时间；
* `n` 表示数据规模的大小；
* `f(n)` 表示每行代码执行的次数总和。
* `O` 表示代码的执行时间 `T(n)` 与 `f(n)` 表达式成正比

所以，上面例子用大 O 时间复杂度表示法表示就是 `T(n) = O(2n+2)`

大 O 时间复杂度实际上并不具体表示代码真正的执行时间，而是表示**代码执行时间随数据规模增长的变化趋势**，所以，也叫作**渐进时间复杂度，简称时间复杂度**。


## 时间复杂度分析

如何分析一段代码的时间复杂度？我这儿有三个比较实用的方法可以分享给你。

### 1. 只关注循环执行次数最多的一段代码

我们在分析一个算法、一段代码的时间复杂度的时候，也只关注循环执行次数最多的那一段代码就可以了。

这段核心代码执行次数的 n 的量级，就是整段要分析代码的时间复杂度。

还是前面的例子, 第 2, 3 行都是常量级执行时间, 对时间复杂度没有什么影响.  我们只关注 for 循环里面的代码就可以了.  循环中的代码被执行了 n 次, 所以复杂度就是  O(n)。

### 2. 加法法则：总复杂度等于量级最大的那段代码的复杂度

先看下面这一段代码:

``` C
int cal(int n) {
   int sum_1 = 0;
   int p = 1;
   for (; p < 100; ++p) {
     sum_1 = sum_1 + p;
   }

   int sum_2 = 0;
   int q = 1;
   for (; q < n; ++q) {
     sum_2 = sum_2 + q;
   }
 
   int sum_3 = 0;
   int i = 1;
   int j = 1;
   for (; i <= n; ++i) {
     j = 1; 
     for (; j <= n; ++j) {
       sum_3 = sum_3 +  i * j;
     }
   }
 
   return sum_1 + sum_2 + sum_3;
 }
```

这上面一有三个循环, 第一个循环里面代码执行了 100 次, 所以是一个常量的执行时间，跟 n 的规模无关。( 这里要记住, 无论常量级执行时间有多大, 都忽略掉, 因为我们研究是算法执行效率与数据规模**增长**的变化趋势. )

第二个循环的复杂度是 O(n), 第三个是 O(n^2).

综合这三段代码的时间复杂度，我们取其中最大的量级。所以，整段代码的时间复杂度就为 O(n^2)。

也就是说：**总的时间复杂度就等于量级最大的那段代码的时间复杂度**

### 3. 乘法法则：嵌套代码的复杂度等于嵌套内外代码复杂度的乘积

如果 `T1(n) = O(f(n))`，`T2(n) = O(g(n))`；那么 `T(n) = T1(n) * T2(n) = O(f(n)) * O(g(n)) = O(f(n) * g(n))`.

落实到具体的代码上，我们可以把乘法法则看成是嵌套循环

``` C
int cal(int n) {
  int ret = 0; 
  int i = 1;
  for (; i < n; ++i) {
    ret = ret + f(i);
  } 
} 
 
int f(int n) {
  int sum = 0;
  int i = 1;
  for (; i < n; ++i) {
    sum = sum + i;
  } 
  return sum;
}
```

我们单独看 `cal()` 函数。假设 `f()` 只是一个普通的操作, 那么 `cal()` 函数的复杂度是 O(n).  但 `f()` 函数的复杂度也是 O(n), 所以 `cal()` 函数的复杂度就是, `T(n) = T1(n) * T2(n) = O(n*n) = O(n^2)`

## 几种常见时间复杂度实例分析

![3723793cc5c810e9d5b06bc95325bf0a](https://i.imgur.com/I1uuKxG.jpg)

我们可以粗略地分为两类，**多项式量级** 和 **非多项式量级**。

![497a3f120b7debee07dc0d03984faf04](https://i.imgur.com/sm2Lima.jpg)

它们所花时间的比较

### 非多项式量级

其中，非多项式量级只有两个：`O(2n)` 和 `O(n!)`。

我们把时间复杂度为非多项式量级的算法问题叫作 **NP**（Non-Deterministic Polynomial，非确定多项式）问题。

当数据规模 n 越来越大时，非多项式量级算法的执行时间会急剧增加, 所以这是一种非常低效的算法

### 多项式量级

#### 1. O(1)

O(1) 只是常量级时间复杂度的一种表示方法，并不是指只执行了一行代码。

只要代码的执行时间不随 n 的增大而增长，这样代码的时间复杂度我们都记作 O(1)。

#### 2. O(logn)、O(nlogn)

对数时间复杂度非常常见，同时也是最难分析的一种时间复杂度。

我们先来看一段代码:

``` C
i=1;

while (i <= n)  {
  i = i * 2;
}
```

从代码中可以看出，变量 i 的值从 1 开始取，每循环一次就乘以 2. 当大于 n 时，循环结束。

实际上，变量 i 的取值就是一个等比数列。

![9b1c88264e7a1a20b5954be9bc4bec9a](https://i.imgur.com/lxW8Dfu.jpg)

所以，我们只要知道 x 值是多少，就知道这行代码执行的次数了

通过 `2 ^ x = n` 求解 `x`. `x = log2n` 这段代码的时间复杂度就是 `O(log2n)`。

实际上，不管是以 2 为底、以 3 为底，还是以 10 为底，我们可以把所有对数阶的时间复杂度都记为 `O(logn)`。

原因很简单, 就拿上面的例子举例.  `O(log2n) = O(logn / log2)`.  `O(log2)` 是一个常量, 我们就把它忽略掉了

#### 3. O(m+n)、O(m*n)

先看代码:

``` C
int cal(int m, int n) {
  int sum_1 = 0;
  int i = 1;
  for (; i < m; ++i) {
    sum_1 = sum_1 + i;
  }

  int sum_2 = 0;
  int j = 1;
  for (; j < n; ++j) {
    sum_2 = sum_2 + j;
  }

  return sum_1 + sum_2;
}
```

从代码中可以看出，m 和 n 是表示两个数据规模。我们无法事先评估 m 和 n 谁的量级大，所以我们在表示复杂度的时候，就不能简单地利用加法法则，省略掉其中一个。所以，上面代码的时间复杂度就是 `O(m+n)`。

## 空间复杂度分析

前面我讲过，时间复杂度的全称是渐进时间复杂度，表示**算法的执行时间与数据规模之间的增长关系**。类比一下，空间复杂度全称就是渐进空间复杂度，表示**算法的存储空间与数据规模之间的增长关系**。

``` C
void print(int n) {
  int i = 0;
  int[] a = new int[n];
  for (i; i <n; ++i) {
    a[i] = i * i;
  }

  for (i = n-1; i >= 0; --i) {
    print out a[i]
  }
}
```

可以看到, 第 2 行代码中，我们申请了一个空间存储变量 i，它是常量阶的，跟数据规模 n 没有关系，所以我们可以忽略。 第 3 行申请了一个大小为 n 的 int 类型数组，除此之外，剩下的代码都没有占用更多的空间，所以整段代码的空间复杂度就是 `O(n)`。

## 时间复杂度进阶知识

### 最好、最坏情况时间复杂度

``` C
// n 表示数组 array 的长度
int find(int[] array, int n, int x) {
  int i = 0;
  int pos = -1;
  for (; i < n; ++i) {
    if (array[i] == x) {
       pos = i;
       break;
    }
  }
  return pos;
}
```

上面这段代码中, 要查找的变量 x 可能出现在数组的任意位置。如果数组中第一个元素正好是要查找的变量 x，那就不需要继续遍历剩下的 n-1 个数据了，那时间复杂度就是 O(1)。但如果数组中不存在变量 x，那我们就需要把整个数组都遍历一遍，时间复杂度就成了 O(n)。

为了表示代码在不同情况下的不同时间复杂度，我们需要引入三个概念：最好情况时间复杂度、最坏情况时间复杂度和平均情况时间复杂度。

**最好情况时间复杂度就是，在最理想的情况下，，执行这段代码的时间复杂度。**

**最坏情况时间复杂度就是，在最糟糕的情况下，执行这段代码的时间复杂度。**

### 平均情况时间复杂度

为了更好地表示平均情况下的复杂度，我们需要引入另一个概念：平均情况时间复杂度，后面我简称为平均时间复杂度

还是拿上面找变量 X 在数组中的位置的例子:

要查找的变量 x 在数组中的位置，有 n+1 种情况：**在数组的 0～n-1 位置中和不在数组中**。

我们把每种情况下，查找需要遍历的元素个数累加起来，然后再除以 n+1，就可以得到需要遍历的元素个数的平均值，即：

![Screen Shot 2018-10-01 at 1.12.28 PM](https://i.imgur.com/8ILNkFg.png)

咱们把刚刚这个公式简化之后，得到的平均时间复杂度就是 `O(n)`

但是上面这种计算方法其实存在问题.  我们知道，要查找的变量 x，要么在数组里，要么就不在数组里。我们假设在数组中与不在数组中的概率都为 1/2。要查找的数据出现在 0～n-1 这 n 个位置的概率也是一样的，为 1/n。根据概率乘法法则，要查找的数据出现在 0～n-1 中任意位置的概率就是 1/(2n)。

前面的推导过程中存在的最大问题就是，没有将各种情况发生的**概率**考虑进去。如果我们把每种情况发生的概率也考虑进去，那平均时间复杂度的计算过程就变成了这样：

![Screen Shot 2018-10-01 at 1.16.45 PM](https://i.imgur.com/FuO0HMx.png)

这个值就是概率论中的**加权平均值**，也叫作**期望值**，所以平均时间复杂度的全称应该叫**加权平均时间复杂度**或者**期望时间复杂度**。

### 均摊时间复杂度

均摊时间复杂度，听起来跟平均时间复杂度有点儿像。大部分情况下，我们并不需要区分最好、最坏、平均三种复杂度。平均复杂度只在某些特殊情况下才会用到，而均摊时间复杂度应用的场景比它更加特殊、更加有限。


下次再说:
[链接](https://time.geekbang.org/column/article/40447)

