# 散列表

散列表的英文叫 “Hash Table”，所以平时也被称为它 “哈希表”。

再说明什么是散列表之前，先假设一个场景。

::: details-open 例子：
假如我们有 89 名选手参加学校运动会。为了方便记录成绩，每个选手胸前都会贴上自己的参赛号码。号码的编号用 6 位数字来表示， 规则是前两位表示年级，中间两位表示班级，最后两位是选手编号(1 - 89)。

现在我们希望编程实现这样一个功能，通过编号快速找到对应的选手信息。 我们知道数组支持按照下标随机访问数据，并且时间复杂度是 $O(1)$。尽管我们不能直接把编号作为数组下标，但我们可以截取参赛编号的后两位作为数组下标，来存取选手信息数据。

当通过参赛编号查询选手信息的时候，我们用同样的方法，取参赛编号的后两位，作为数组下标，来读取数组中的数据。
:::

上例就是典型的散列思想。其中：

- 参赛选手的编号我们叫作**键**（key）或者**关键字**。我们用它来标识一个选手；
- 我们把参赛编号转化为数组下标的映射方法就叫作**散列函数**（哈希函数）；
- 散列函数计算得到的值就叫作**散列值**（哈希值）；

![2020-1-14-16-15-27.png](https://garrik-default-imgs.oss-accelerate.aliyuncs.com/imgs/2020-1-14-16-15-27.png)

总结一下：

- 散列表利用了数组支持按照下标随机访问的时候，时间复杂度是 O(1) 的特性；
- 我们通过散列函数把元素的键值映射为下标，然后将数据存储在数组中对应下标的位置；
- 当我们按照键值查询元素时，我们用同样的散列函数，将键值转化数组下标，从对应的数组下标的位置取数据；

## 散列函数

散列函数，我们可以把它定义成 `hash(key)`，其中 `key` 表示元素的键值，`hash(key)` 的值表示经过散列函数计算得到的散列值。

刚刚举的学校运动会的例子，散列函数比较简单，也比较容易想到。但是，如果参赛选手的编号是随机生成的 6 位数字，又或者用的是 a 到 z 之间的字符串，该如何构造散列函数呢？

**散列函数设计的基本要求**：

- 散列函数计算得到的散列值是一个非负整数；
- 如果 $key1 = key2$，那 $hash(key1) == hash(key2)$；
- 如果 $key1 ≠ key2$，那 $hash(key1) ≠ hash(key2)$；

上面三条中，第一点理解起来应该没有任何问题。因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。第一点理解起来应该没有任何问题。因为数组下标是从 0 开始的，所以散列函数生成的散列值也要是非负整数。

而第三条，**在真实的情况下，要想找到一个不同的 key 对应的散列值都不一样的散列函数，几乎是不可能的**。即便像业界著名的 MD5、SHA、CRC 等哈希算法，也无法完全避免这种散列冲突。而且，因为数组的存储空间有限，也会加大散列冲突的概率

## 散列冲突

想通过写一个完美的散列函数来结局冲突问题，成本太大。我们需要通过其他途径来解决。常用的散列冲突解决方法有两类，**开放寻址法**（open addressing）和**链表法**（chaining）。

### 开放寻址法

核心思想是，**如果出现了散列冲突，我们就重新探测一个空闲位置，将其插入**。

#### 线性探测法

一个比较简单的探测方法，**线性探测**（Linear Probing）：

当我们往散列表中插入数据时，如果某个数据经过散列函数散列之后，存储位置已经被占用了，我们就从当前位置开始，依次往后查找，看是否有空闲位置，直到找到为止。

在散列表中查找元素的过程有点儿类似插入过程。我们通过散列函数求出要查找元素的键值对应的散列值，然后比较数组中下标为散列值的元素和要查找的元素。如果相等，则说明就是我们要找的元素；否则就顺序往后依次查找。如果遍历到数组中的空闲位置，还没有找到，就说明要查找的元素并没有在散列表中。

::: details-open 例子：
![2020-1-14-16-36-8.png](https://garrik-default-imgs.oss-accelerate.aliyuncs.com/imgs/2020-1-14-16-36-8.png)

从图中可以看出，散列表的大小为 10，在元素 x 插入散列表之前，已经 6 个元素插入到散列表中。x 经过 Hash 算法之后，被散列到位置下标为 7 的位置，但是这个位置已经有数据了，所以就产生了冲突。于是我们就顺序地往后一个一个找，看有没有空闲的位置，遍历到尾部都没有找到空闲的位置，于是我们再从表头开始找，直到找到空闲位置 2，于是将其插入到这个位置。
:::

通过上面线性探测方法，找到一个空闲位置，我们就可以认定散列表中不存在这个数据。但是，如果这个空闲位置是我们后来删除的，就会导致原来的查找算法失效。本来存在的数据，会被认定为不存在。

解决办法是我们可以将删除的元素，特殊标记为 `deleted`。当线性探测查找的时候，遇到标记为 `deleted` 的空间，并不是停下来，而是继续往下探测。

![2020-1-14-16-39-27.png](https://garrik-default-imgs.oss-accelerate.aliyuncs.com/imgs/2020-1-14-16-39-27.png)

**线性探测法其实存在很大问题。当散列表中插入的数据越来越多时，散列冲突发生的可能性就会越来越大，空闲位置会越来越少，线性探测的时间就会越来越久**。极端情况下，我们可能需要探测整个散列表。

#### 二次探测法

二次探测，跟线性探测很像，线性探测每次探测的步长是 $1$，它探测的下标序列就是 $hash(key)+0$，$hash(key)+1$，$hash(key)+2$ $......$

**二次探测法将每次探测的步长变成了原来的 “二次方”**，也就是说，它探测的下标序列就是 $hash(key)+0$，$hash(key)+1^2$，$hash(key)+2^2$ $......$

#### 双重散列法

**所谓双重散列，意思就是使用不仅一个散列函数**。我们先用第一个散列函数，如果计算得到的存储位置已经被占用，再用第二个散列函数，依次类推，直到找到空闲的存储位置。

### 链表法

链表法是一种更加常用的散列冲突解决办法。我们将散列表中的每个位置看作是一个“桶”（bucket）或者 “槽”（slot）。**每个槽会对应一条链表，所有散列值相同的元素我们都放到相同槽位对应的链表中**。

![2020-1-14-16-55-42.png](https://garrik-default-imgs.oss-accelerate.aliyuncs.com/imgs/2020-1-14-16-55-42.png)

**当插入的时候，我们只需要通过散列函数计算出对应的散列槽位，将其插入到对应链表中即可**，所以插入的时间复杂度是 $O(1)$。**当查找、删除一个元素时，我们同样通过散列函数计算出对应的槽，然后遍历链表查找或者删除**。

查找或删除操作的时间复杂度跟链表的长度 $k$ 成正比，也就是 $O(k)$。对于散列比较均匀的散列函数来说，理论上讲，$k=n/m$，其中 n 表示散列中数据的个数，$m$ 表示散列表中 “槽” 的个数。

### 优缺点对比

#### 开放寻址法

**优点**：

散列表中的数据都存储在数组中，可以有效地利用 CPU 缓存加快查询速度。而且，这种方法实现的散列表，序列化起来比较简单。链表法包含指针，序列化起来就没那么容易。

> **序列化** (Serialization) 是将对象的状态信息转换为可以存储或传输的形式的过程。 在序列化期间，对象将其当前状态写入到临时或持久性存储区。 以后，可以通过从存储区中读取或反序列化对象的状态，重新创建该对象。

**缺点**：

之前说，用开放寻址法解决冲突的散列表，删除数据的时候需要特殊标记已经删除掉的数据。而且，在开放寻址法中，所有的数据都存储在一个数组中，比起链表法来说，冲突的代价更高。所以，使用开放寻址法解决冲突的散列表，装载因子的上限不能太大。这也导致这种方法比链表法更浪费内存空间。

**使用场景**：总结来讲，当数据量比较小、装载因子小的时候，适合采用开放寻址法。

#### 链表法

**优点**：

链表法对内存的利用率比开放寻址法要高。因为链表结点可以在需要的时候再创建，并不需要像开放寻址法那样事先申请好。

链表法比起开放寻址法，对大装载因子的容忍度更高。开放寻址法只能适用装载因子小于 1 的情况。接近 1 时，就可能会有大量的散列冲突，导致大量的探测、再散列等，性能会下降很多。但是对于链表法来说，只要散列函数的值随机均匀，即便装载因子变成 10，也就是链表的长度变长了而已，虽然查找效率有所下降，但是比起顺序查找还是快很多。

**缺点**：

对于比较小的数据的存储，是比较消耗内存的，还有可能会让内存的消耗翻倍。而且，因为链表中的结点是零散分布在内存中的，不是连续的，所以对 CPU 缓存是不友好的，这方面对于执行效率也有一定的影响。

**使用场景**：基于链表的散列冲突处理方法比较适合存储大对象、大数据量的散列表，而且，比起开放寻址法，它更加灵活，支持更多的优化策略，比如用红黑树代替链表。

## 装载因子

不管采用哪种方法解决散列冲突，当散列表中空闲位置不多的时候，散列冲突的概率就会大大提高。为了尽可能保证散列表的操作效率，一般情况下，**会尽可能保证散列表中有一定比例的空闲槽位**。我们用**装载因子**（load factor）来表示空位的多少。**装载因子越大，说明空闲位置越少，冲突越多，散列表的性能会下降**。

装载因子的计算公式是：

$装载因子 = 填入表中的元素个数 / 散列表的长度$

### 动态扩容 & 动态缩容

对于有频繁插入和删除操作的动态散列表来说，数据集合是频繁变动的，我们事先无法预估将要加入的数据个数，所以我们也无法事先申请一个足够大的散列表。随着数据慢慢加入，装载因子就会慢慢变大。当装载因子大到一定程度之后，散列冲突就会变得不可接受。这个时候，我们该如何处理呢？

我们可以采用数组 “**动态扩容**” 的做法。但因为散列表的大小变了，数据的存储位置也变了，所以我们需要通过散列函数重新计算每个数据的存储位置。

对于动态散列表，随着数据的删除，散列表中的数据会越来越少，空闲空间会越来越多。如果我们对空间消耗非常敏感，我们可以在装载因子小于某个值之后，启动 “**动态缩容**”。

### 如何提高扩容效率

当装载因子已经到达阈值，需要先进行扩容，再插入数据。这个操作的时间复杂度比单独进行插入数据要大。如果散列表数据很多，时间上就可能会让人无法接受。

为了解决一次性扩容耗时过多的情况，我们可以**将扩容操作穿插在插入操作的过程中，分批完成**：

- 当装载因子触达阈值之后，我们只申请新空间，但并不将老的数据搬移到新散列表中；
- 当有新数据要插入时，我们将新数据插入新散列表中，并且从老的散列表中拿出一个数据放入到新散列表。每次插入一个数据到散列表，我们都重复上面的过程；
- 经过多次插入操作之后，老的散列表中的数据就一点一点全部搬移到新散列表中了；

这种实现方式，任何情况下，插入一个数据的时间复杂度都是 $O(1)$。

![2020-1-14-17-43-30.png](https://garrik-default-imgs.oss-accelerate.aliyuncs.com/imgs/2020-1-14-17-43-30.png)

对于查询操作，为了兼容了新、老散列表中的数据，我们先从新散列表中查找，如果没有找到，再去老的散列表中查找。

## 工业级散列表举例分析

下面看看 Java 中的 HashMap 这样一个工业级的散列表是如何应用上面所讲的  技术的。

#### 初始大小

**HashMap 默认的初始大小是 16**，如果事先知道大概的数据量有多大，可以通过修改默认初始大小，减少动态扩容的次数，这样会大大提高 HashMap 的性能。

#### 装载因子和动态扩容

**最大装载因子默认是 0.75**，当 HashMap 中元素个数超过 $0.75 * capacity$（散列表的容量）的时候，就会启动扩容，**每次扩容都会扩容为原来的两倍大小**。

#### 散列冲突解决方法

**HashMap 底层采用链表法来解决冲突**。即使负载因子和散列函数设计得再合理，也免不了会出现拉链过长的情况，一旦出现拉链过长，则会严重影响 HashMap 的性能。

在 JDK1.8 版本中，用 “红黑树” 对 HashMap 做进一步优化，**当链表长度太长（默认超过 8）时，链表就转换为红黑树**。我们可以利用红黑树快速增删改查的特点，提高 HashMap 的性能。**当红黑树结点个数少于 8 个的时候，又会将红黑树转化为链表**。因为在数据量较小的情况下，红黑树要维护平衡，比起链表来，性能上的优势并不明显。

#### 散列函数

散列函数的设计并不复杂，追求的是简单高效、分布均匀：

```java

int hash(Object key) {
  int h = key.hashCode()；
  // capicity 表示散列表的大小
  return (h ^ (h >>> 16)) & (capicity -1);
}
```

其中，`hashCode()` 返回的是 Java 对象的 Hash Code。比如 String 类型的对象的 `hashCode()` 就是下面这样：

```java

public int hashCode() {
  int var1 = this.hash;
  if(var1 == 0 && this.value.length > 0) {
    char[] var2 = this.value;
    for(int var3 = 0; var3 < this.value.length; ++var3) {
      var1 = 31 * var1 + var2[var3];
    }
    this.hash = var1;
  }
  return var1;
}
```

#### 总结

**如何设计的一个工业级的散列函数**？如果这是一道面试题或者是摆在你面前的实际开发问题，你会从哪几个方面思考呢？

首先思考，工业级的散列表应该具有哪些特性？结合已经学习过的散列知识，应该有这样几点要求：

- **支持快速的查询、插入、删除操作**；
- **内存占用合理**，不能浪费过多的内存空间；
- **性能稳定**，极端情况下，散列表的性能也不会退化到无法接受的情况；

如何实现这样一个散列表呢？根据前面讲到的知识，应该从这三个方面来考虑设计思路：

- **设计一个合适的散列函数**；
- **定义装载因子阈值，并且设计动态扩容策略**；
- **选择合适的散列冲突解决方法**；

## “散列表 & 链表” 结合使用

下面讲一下如何在 “LRU 缓存淘汰算法”  中结合使用 “散列表” 和 “链表”

先让我们回顾下，之前如何通过链表实现 LRU 缓存淘汰算法的：

- 需要维护一个按照访问时间从后到前有序排列的链表结构。因为缓存大小有限，当缓存空间不够，需要淘汰一个数据的时候，我们就直接将链表头部的结点删除；
- 当要缓存某个数据的时候，先在链表中查找这个数据。如果没有找到，则直接将数据放到链表的尾部；如果找到了，我们就把它移动到链表的尾部；

因为查找数据需要遍历链表，所以单纯用链表实现的 LRU 缓存淘汰算法的时间复杂很高，是 $O(n)$。

总结一下，一个缓存（cache）系统主要包含下面这几个操作：

- 往缓存中添加一个数据；
- 从缓存中删除一个数据；
- 在缓存中查找一个数据；

如果我们将散列表和链表两种数据结构组合使用，可以将这三个操作的时间复杂度都降低到 $O(1)$。

![2020-1-14-18-24-24.png](https://garrik-default-imgs.oss-accelerate.aliyuncs.com/imgs/2020-1-14-18-24-24.png)

我们使用双向链表存储数据，链表中的每个结点处理存储数据（data）、前驱指针（prev）、后继指针（next）之外，还新增了一个特殊的字段 **hnext**。

因为我们的散列表是通过链表法解决散列冲突的，所以每个结点会在两条链中。一个链是**双向链表**，另一个链是散列表中的**拉链**。

我们再来看，前面讲到的缓存的三个操作，是如何做到时间复杂度是 $O(1)$ 的：

- **查找一个数据**：散列表中查找数据的时间复杂度接近 $O(1)$，通过散列表，我们可以很快地在缓存中找到一个数据。当找到数据之后，我们还需要将它移动到双向链表的尾部。
- **删除一个数据**：需要找到数据所在的结点，然后将结点删除。借助散列表，我们可以在 $O(1)$ 时间复杂度里找到要删除的结点。因为我们的链表是双向链表，双向链表可以通过前驱指针 $O(1)$ 时间复杂度获取前驱结点，所以在双向链表中，删除结点只需要 $O(1)$ 的时间复杂度。
- **添加一个数据**：添加数据到缓存稍需要先看这个数据是否已经在缓存中。如果已经在其中，需要将其移动到双向链表的尾部；如果不在其中，还要看缓存有没有满。如果满了，则将双向链表头部的结点删除，然后再将数据放到链表的尾部；如果没有满，就直接将数据放到链表的尾部。

## 哈希算法（散列算法）

哈希算法历史悠久，业界著名的哈希算法也有很多，比如 MD5、SHA 等。在我们平时的开发中，基本上都是拿现成的直接用。这一节主要讲解，在实际的开发中，我们该如何用哈希算法解决问题。

哈希算法的定义和原理非常简单：**将任意长度的二进制值串映射为固定长度的二进制值串**。这个映射的规则就是哈希算法，而通过原始数据映射之后得到的二进制值串就是**哈希值**。

一个优秀的哈希算法，需要满足几点要求：

- **从哈希值不能反向推导出原始数据**（所以哈希算法也叫单向哈希算法）；
- **对输入数据非常敏感**，哪怕原始数据只修改了一个 Bit，最后得到的哈希值也大不相同；
- **散列冲突的概率要很小**，对于不同的原始数据，哈希值相同的概率非常小；
- 哈希算法的**执行效率要尽量高效**，针对较长的文本，也能快速地计算出哈希值；

哈希算法的应用非常非常多，最常见的七个，分别是**安全加密**、**唯一标识**、**数据校验**、**散列函数**、**负载均衡**、**数据分片**、**分布式存储**。

#### 应用一：安全加密

最常用于加密的哈希算法是 **MD5**（MD5 Message-Digest Algorithm，MD5 消息摘要算法）和 **SHA**（Secure Hash Algorithm，安全散列算法）。

讲到的哈希算法四点要求，对用于加密的哈希算法来说，有两点格外重要：

1. 很难根据哈希值反向推导出原始数据；
2. 散列冲突的概率要很小；

**为什么哈希算法无法做到零冲突？**

离散数学有个基础理论，**鸽巢原理**。这个理论说它，如果有 10 个鸽巢，有 11 只鸽子，那肯定有 1 个鸽巢中的鸽子数量多于 1 个。

**哈希算法产生的哈希值的长度是固定且有限的**。比如前面举的 MD5 的例子，哈希值是固定的 128 位二进制串，**能表示的数据是有限的**，最多能表示 2^128 个数据，而我们要哈希的数据是无穷的。基于鸽巢原理，如果我们对 2^128+1 个数据求哈希值，就必然会存在哈希值相同的情况。

#### 应用二：唯一标识

下面通过一个例子来说明：

我们知道，任何文件在计算中都可以表示成二进制码串。如果要在海量的图库中，搜索一张图是否存在。比较笨的办法就是，拿要查找的图片的二进制码串与图库中所有图片的二进制码串进行比对。但是，每个图片小则几十 KB、大则几 MB，转化成二进制是一个非常长的串，比对起来非常耗时。

我们可以从图片的二进制码串开头取 100 个字节，从中间取 100 个字节，从最后再取 100 个字节，然后将这 300 个字节放到一块，通过哈希算法（比如 MD5），得到一个哈希字符串，用它作为图片的唯一标识。通过这个唯一标识来判定图片是否在图库中，这样就可以减少很多工作量。

#### 应用三：数据校验

BT 下载的原理是基于 P2P 协议的。我们从多个机器上并行下载一个 2GB 的电影，这个电影文件可能会被分割成很多文件块（比如可以分成 100 块，每块大约 20MB）。等所有的文件块都下载完成之后，再组装成一个完整的电影文件。

我们知道，网络传输是不安全的，下载的文件块有可能是被宿主机器恶意修改过的，又或者下载过程中出现了错误，所以下载的文件块可能不是完整的。

我们可以通过哈希算法，对 100 个文件块分别取哈希值，并且保存在种子文件中。我们在前面讲过，哈希算法有一个特点，对数据很敏感。只要文件块的内容有一丁点儿的改变，最后计算出的哈希值就会完全不同。所以，当文件块下载完成之后，我们可以通过相同的哈希算法，对下载好的文件块逐一求哈希值，然后跟种子文件中保存的哈希值比对。

#### 应用四：散列函数

前面说，散列函数是设计一个散列表的关键。它直接决定了散列冲突的概率和散列表的性能。不过，相对哈希算法的其他应用，散列函数对于散列算法冲突的要求要低很多。即便出现个别散列冲突，只要不是过于严重，我们都可以通过开放寻址法或者链表法解决。

散列函数对于散列算法计算得到的值，是否能反向解密也并不关心。散列函数中用到的散列算法，更加关注散列后的值是否能平均分布，也就是，一组数据是否能均匀地散列在各个槽中。除此之外，散列函数执行的快慢，也会影响散列表的性能，所以，散列函数用的散列算法一般都比较简单，比较追求效率。

#### 应用五：负载均衡

负载均衡算法有很多，比如轮询、随机、加权轮询等。那如何才能实现一个会话粘滞（session sticky）的负载均衡算法呢？也就是说，我们需要在同一个客户端上，在一次会话中的所有请求都路由到同一个服务器上。

最直接的方法就是，维护一张映射关系表，这张表的内容是客户端 IP 地址或者会话 ID 与服务器编号的映射关系。客户端发出的每次请求，都要先在映射表中查找应该路由到的服务器编号，然后再请求编号对应的服务器。但这样做有几个弊端：

- 如果客户端很多，映射表可能会很大，比较浪费内存空间；
- 客户端下线、上线，服务器扩容、缩容都会导致映射失效，这样维护映射表的成本就会很大；

我们可以**通过哈希算法，对客户端 IP 地址或者会话 ID 计算哈希值，将取得的哈希值与服务器列表的大小进行取模运算，最终得到的值就是应该被路由到的服务器编号**。 这样，我们就可以把同一个 IP 过来的所有请求，都路由到同一个后端服务器上。

#### 应用六：数据分片

假如我们有 1T 的日志文件，这里面记录了用户的搜索关键词，我们想要快速统计出每个关键词被搜索的次数，该怎么做呢？

这个问题有两个难点，第一个是搜索日志很大，没办法放到一台机器的内存中。第二个难点是，如果只用一台机器来处理这么巨大的数据，处理时间会很长。

针对这两个难点，**我们可以先对数据进行分片，然后采用多台机器处理的方法，来提高处理速度**。具体的思路是这样的：为了提高处理的速度，我们用 n 台机器并行处理。我们从搜索记录的日志文件中，依次读出每个搜索关键词，并且通过哈希函数计算哈希值，然后再跟 n 取模，最终得到的值，就是应该被分配到的机器编号。

这样，哈希值相同的搜索关键词就被分配到了同一个机器上。也就是说，同一个搜索关键词会被分配到同一个机器上。每个机器会分别计算关键词出现的次数，最后合并起来就是最终的结果。

#### 应用七：分布式存储

现在互联网面对的都是海量的数据、海量的用户。我们为了提高数据的读取、写入能力，一般都采用分布式的方式来存储数据，比如分布式缓存。我们有海量的数据需要缓存，所以一个缓存机器肯定是不够的。于是，我们就需要将数据分布在多台机器上。

该如何决定将哪个数据放到哪个机器上呢？我们可以借用前面数据分片的思想，即通过哈希算法对数据取哈希值，然后对机器个数取模，这个最终值就是应该存储的缓存机器编号。

但是，如果数据增多，原来的 10 个机器已经无法承受了，我们就需要扩容了，比如扩到 11 个机器，这里并不是简单地加个机器就可以了。原来的数据是通过与 10 来取模的。比如 13 这个数据，存储在编号为 3 这台机器上。但是新加了一台机器中，我们对数据按照 11 取模，原来 13 这个数据就被分配到 2 号这台机器上了。

因此，所有的数据都要重新计算哈希值，然后重新搬移到正确的机器上。这样就相当于，缓存中的数据一下子就都失效了。所有的数据请求都会直接去请求数据库。

所以，我们需要一种方法，使得在新加入一个机器后，并不需要做大量的数据搬移。这时候，**一致性哈希算法**就要登场了。

假设我们有 k 个机器，数据的哈希值的范围是 [0, MAX]。我们将整个范围划分成 m 个小区间（m 远大于 k），每个机器负责 m/k 个小区间。当有新机器加入的时候，我们就将某几个小区间的数据，从原来的机器中搬移到新的机器中。这样，既不用全部重新哈希、搬移数据，也保持了各个机器上数据数量的均衡。
